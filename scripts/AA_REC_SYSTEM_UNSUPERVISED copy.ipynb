{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250666, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_clean/merged_total.csv')\n",
    "df.fillna('unknown', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\storm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\storm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['afspraak_keyphrases', 'account_keyphrases', 'campagne_keyphrases',\n",
       "       'sessie_keyphrases', 'visit_keyphrases', 'mailing_keyphrases'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "cat_cols = cat_cols[(cat_cols != 'visit_bounce') & (cat_cols != 'contact_contactpersoon_id') & (cat_cols != 'account_account_id')]\n",
    "\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afspraak_keyphrases</th>\n",
       "      <th>account_keyphrases</th>\n",
       "      <th>campagne_keyphrases</th>\n",
       "      <th>sessie_keyphrases</th>\n",
       "      <th>visit_keyphrases</th>\n",
       "      <th>mailing_keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>familiebedrijf, diensten, vastgoed, melle gent...</td>\n",
       "      <td>offline, netwerkevenement, ov kick off communi...</td>\n",
       "      <td>ma events, netwerking, netwerkactiviteit project</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>bedrijf, diensten, consultancy, geraardsbergen...</td>\n",
       "      <td>offline, opleiding, corona round tables sales</td>\n",
       "      <td>gr werking, marketing sales, opleidingen</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retentie lidmaatschap, ledenbezoek 2023, indus...</td>\n",
       "      <td>bedrijf, diensten, milieu, meilegem oudenaarde...</td>\n",
       "      <td>offline, netwerkevenement, nw nieuwjaarsrecept...</td>\n",
       "      <td>nw voka connect gent, netwerking, netwerkactiv...</td>\n",
       "      <td>chrome, windows, ghent, belgium, pro, event su...</td>\n",
       "      <td>jo stamgasten 2023, uitnodiging stamgasten 23 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retentie lidmaatschap, ledenbezoek 2023, indus...</td>\n",
       "      <td>bedrijf, diensten, milieu, meilegem oudenaarde...</td>\n",
       "      <td>offline, netwerkevenement, nw nieuwjaarsrecept...</td>\n",
       "      <td>nw voka connect gent, netwerking, netwerkactiv...</td>\n",
       "      <td>chrome, windows, ghent, belgium, telenet, acti...</td>\n",
       "      <td>nw nieuwjaarsreceptie vlaamse ardennen leiestr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retentie lidmaatschap, ledenbezoek 2023, indus...</td>\n",
       "      <td>bedrijf, diensten, milieu, meilegem oudenaarde...</td>\n",
       "      <td>offline, netwerkevenement, nw nieuwjaarsrecept...</td>\n",
       "      <td>nw voka connect gent, netwerking, netwerkactiv...</td>\n",
       "      <td>chrome, windows, ghent, belgium, pro, activite...</td>\n",
       "      <td>nieuwsbrief 09052023, nieuws van voka oost vla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 afspraak_keyphrases  \\\n",
       "0                                                  ,   \n",
       "1                                                  ,   \n",
       "2  retentie lidmaatschap, ledenbezoek 2023, indus...   \n",
       "3  retentie lidmaatschap, ledenbezoek 2023, indus...   \n",
       "4  retentie lidmaatschap, ledenbezoek 2023, indus...   \n",
       "\n",
       "                                  account_keyphrases  \\\n",
       "0  familiebedrijf, diensten, vastgoed, melle gent...   \n",
       "1  bedrijf, diensten, consultancy, geraardsbergen...   \n",
       "2  bedrijf, diensten, milieu, meilegem oudenaarde...   \n",
       "3  bedrijf, diensten, milieu, meilegem oudenaarde...   \n",
       "4  bedrijf, diensten, milieu, meilegem oudenaarde...   \n",
       "\n",
       "                                 campagne_keyphrases  \\\n",
       "0  offline, netwerkevenement, ov kick off communi...   \n",
       "1      offline, opleiding, corona round tables sales   \n",
       "2  offline, netwerkevenement, nw nieuwjaarsrecept...   \n",
       "3  offline, netwerkevenement, nw nieuwjaarsrecept...   \n",
       "4  offline, netwerkevenement, nw nieuwjaarsrecept...   \n",
       "\n",
       "                                   sessie_keyphrases  \\\n",
       "0   ma events, netwerking, netwerkactiviteit project   \n",
       "1           gr werking, marketing sales, opleidingen   \n",
       "2  nw voka connect gent, netwerking, netwerkactiv...   \n",
       "3  nw voka connect gent, netwerking, netwerkactiv...   \n",
       "4  nw voka connect gent, netwerking, netwerkactiv...   \n",
       "\n",
       "                                    visit_keyphrases  \\\n",
       "0                                            unknown   \n",
       "1                                            unknown   \n",
       "2  chrome, windows, ghent, belgium, pro, event su...   \n",
       "3  chrome, windows, ghent, belgium, telenet, acti...   \n",
       "4  chrome, windows, ghent, belgium, pro, activite...   \n",
       "\n",
       "                                  mailing_keyphrases  \n",
       "0                                            unknown  \n",
       "1                                            unknown  \n",
       "2  jo stamgasten 2023, uitnodiging stamgasten 23 ...  \n",
       "3  nw nieuwjaarsreceptie vlaamse ardennen leiestr...  \n",
       "4  nieuwsbrief 09052023, nieuws van voka oost vla...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "for col in cat_cols:\n",
    "  print(\"now working on: \", col)\n",
    "  for i in range(len(df)):\n",
    "    df[col][i] = word_tokenize(df[col][i])\n",
    "\n",
    "\n",
    "df[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['afspraak_keyphrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='dutch')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words_nl = set(stopwords.words('dutch'))\n",
    "    \n",
    "    word_tokens = word_tokenize(text, language='dutch')\n",
    "\n",
    "    result = [x for x in word_tokens if x not in stop_words_nl]\n",
    "\n",
    "    seperator = ', '\n",
    "    return seperator.join(result)\n",
    "\n",
    "\n",
    "def team_name_change(text):\n",
    "    teams_dict = {\n",
    "        'jo': ' jong ondernemen ',\n",
    "        'do': ' duurzaam ondernemen ',\n",
    "        'in': ' innovatie digitalisering ',\n",
    "        'io': ' internationaal ondernemen ',\n",
    "        'ao': ' arbeidsmarkt ',\n",
    "        'ex': ' expert ',\n",
    "        'gr': ' groei ',\n",
    "        'bb': ' belangenbehartiging ',\n",
    "        'co': ' communicatie ',\n",
    "        'nw': ' netwerking ',\n",
    "        'ha': ' haven ',\n",
    "        'ma': ' match '\n",
    "    }\n",
    "    word_tokens = word_tokenize(text, language='dutch')\n",
    "    # apply dict to list\n",
    "    result = [teams_dict.get(word, word) for word in word_tokens]\n",
    "    # join list to string\n",
    "    cleaned_list = ', '.join(result)\n",
    "    # tokenize string\n",
    "    tokenize_list = word_tokenize(cleaned_list, language='dutch')\n",
    "    # remove comma\n",
    "    tokenize_list_no_comma = [x for x in tokenize_list if x != ',']\n",
    "    # join list to string and remove duplicates from list\n",
    "    return ', '.join(list(set(tokenize_list_no_comma)))\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "#   print(\"-------------------\")\n",
    "#   print(\"voor\")\n",
    "#   print(df_clean['campagne_keyphrases'][i])\n",
    "#   print(\"na\")\n",
    "#   stem_sentence=[]\n",
    "#   for word in df_clean['campagne_keyphrases'][i].split(','):\n",
    "#     stem_sentence.append(stemmer.stem(word))\n",
    "#   stem_sentence= ', '.join(stem_sentence)\n",
    "#   print(stem_sentence)\n",
    "\n",
    "def stemmer(text):\n",
    "    stem_sentence=[]\n",
    "    for word in text.split(','):\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "    stem_sentence= ', '.join(stem_sentence)\n",
    "    return stem_sentence\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(df, cat_cols=cat_cols):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        for row in range(len(df)):\n",
    "            name_change = team_name_change(df[col][row])\n",
    "            no_stopwords = remove_stopwords(name_change)\n",
    "            tokenize_list = word_tokenize(no_stopwords, language='dutch')\n",
    "            tokenize_list = [x for x in tokenize_list if x != ',']\n",
    "            stemmer_list = []\n",
    "            for word in tokenize_list:\n",
    "                stemmer_list.append(stemmer.stem(word))\n",
    "            df_copy.at[row, col] = ', '.join(list(set(stemmer_list)))\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def flatten_vector_columns(df, col):\n",
    "    # Flatten the 'vector_column' into a matrix (with padding)\n",
    "    max_vector_length = max(len(vector) for vector in df[col])\n",
    "    padded_matrix = np.array([vector + [0.0] * (max_vector_length - len(vector)) for vector in df[col]])\n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duurt 11.5 minuten om df_clean te maken (10cores) 30 min (4cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_text(df=df, cat_cols=cat_cols)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afspraak_keyphrases</th>\n",
       "      <th>account_keyphrases</th>\n",
       "      <th>campagne_keyphrases</th>\n",
       "      <th>sessie_keyphrases</th>\n",
       "      <th>visit_keyphrases</th>\n",
       "      <th>mailing_keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>vastgoed, familiebedrijf, gent, melle, dienste...</td>\n",
       "      <td>vastgoed, netwerkevenement, ov, kick, bouw, of...</td>\n",
       "      <td>project, netwerking, match, events, netwerkact...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>aalst, geraardsbergen, bedrijf, zaakvoerder, b...</td>\n",
       "      <td>opleiding, sales, offline, corona, tables, round</td>\n",
       "      <td>sales, marketing, werking, groei, opleidingen</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context, tussenpersoon, risico, verwerking, vo...</td>\n",
       "      <td>meilegem, bedrijf, bedrijfsleider, contact, li...</td>\n",
       "      <td>nieuwjaarsreceptie, netwerkevenement, netwerki...</td>\n",
       "      <td>netwerking, voka, provinciaal, gent, netwerkac...</td>\n",
       "      <td>ghent, event, sessions, mail, windows, belgium...</td>\n",
       "      <td>stamgasten, 23, jong, ondernemen, mei, 2023, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context, tussenpersoon, risico, verwerking, vo...</td>\n",
       "      <td>meilegem, bedrijf, bedrijfsleider, contact, li...</td>\n",
       "      <td>nieuwjaarsreceptie, netwerkevenement, netwerki...</td>\n",
       "      <td>netwerking, voka, provinciaal, gent, netwerkac...</td>\n",
       "      <td>ghent, nieuwjaarsreceptie, activiteiten, windo...</td>\n",
       "      <td>nieuwjaarsreceptie, netwerking, voka, vlaamse,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>context, tussenpersoon, risico, verwerking, vo...</td>\n",
       "      <td>meilegem, bedrijf, bedrijfsleider, contact, li...</td>\n",
       "      <td>nieuwjaarsreceptie, netwerkevenement, netwerki...</td>\n",
       "      <td>netwerking, voka, provinciaal, gent, netwerkac...</td>\n",
       "      <td>ghent, activiteiten, mail, windows, financieel...</td>\n",
       "      <td>inbox, digitalisering, 09052023, nieuwsbrief, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 afspraak_keyphrases  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  context, tussenpersoon, risico, verwerking, vo...   \n",
       "3  context, tussenpersoon, risico, verwerking, vo...   \n",
       "4  context, tussenpersoon, risico, verwerking, vo...   \n",
       "\n",
       "                                  account_keyphrases  \\\n",
       "0  vastgoed, familiebedrijf, gent, melle, dienste...   \n",
       "1  aalst, geraardsbergen, bedrijf, zaakvoerder, b...   \n",
       "2  meilegem, bedrijf, bedrijfsleider, contact, li...   \n",
       "3  meilegem, bedrijf, bedrijfsleider, contact, li...   \n",
       "4  meilegem, bedrijf, bedrijfsleider, contact, li...   \n",
       "\n",
       "                                 campagne_keyphrases  \\\n",
       "0  vastgoed, netwerkevenement, ov, kick, bouw, of...   \n",
       "1   opleiding, sales, offline, corona, tables, round   \n",
       "2  nieuwjaarsreceptie, netwerkevenement, netwerki...   \n",
       "3  nieuwjaarsreceptie, netwerkevenement, netwerki...   \n",
       "4  nieuwjaarsreceptie, netwerkevenement, netwerki...   \n",
       "\n",
       "                                   sessie_keyphrases  \\\n",
       "0  project, netwerking, match, events, netwerkact...   \n",
       "1      sales, marketing, werking, groei, opleidingen   \n",
       "2  netwerking, voka, provinciaal, gent, netwerkac...   \n",
       "3  netwerking, voka, provinciaal, gent, netwerkac...   \n",
       "4  netwerking, voka, provinciaal, gent, netwerkac...   \n",
       "\n",
       "                                    visit_keyphrases  \\\n",
       "0                                            unknown   \n",
       "1                                            unknown   \n",
       "2  ghent, event, sessions, mail, windows, belgium...   \n",
       "3  ghent, nieuwjaarsreceptie, activiteiten, windo...   \n",
       "4  ghent, activiteiten, mail, windows, financieel...   \n",
       "\n",
       "                                  mailing_keyphrases  \n",
       "0                                            unknown  \n",
       "1                                            unknown  \n",
       "2  stamgasten, 23, jong, ondernemen, mei, 2023, u...  \n",
       "3  nieuwjaarsreceptie, netwerking, voka, vlaamse,...  \n",
       "4  inbox, digitalisering, 09052023, nieuwsbrief, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].str.replace(r'\\d', '', regex=True).str.replace(', ,', ',')\n",
    "    df_clean[col] = df_clean[col].apply(lambda x: 'unknown' if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['campagne_keyphrases'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "voor\n",
      "vastgoed, netwerkevenement, ov, kick, bouw, offline, community, off\n",
      "na\n",
      "vastgoed,  netwerkevenement,  ov,  kick,  bouw,  offlin,  community,  off\n",
      "-------------------\n",
      "voor\n",
      "opleiding, sales, offline, corona, tables, round\n",
      "na\n",
      "opleid,  sales,  offlin,  corona,  tables,  round\n",
      "-------------------\n",
      "voor\n",
      "nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen\n",
      "na\n",
      "nieuwjaarsreceptie,  netwerkevenement,  netwerk,  oost,  regio,  offlin,  vlaander\n",
      "-------------------\n",
      "voor\n",
      "nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen\n",
      "na\n",
      "nieuwjaarsreceptie,  netwerkevenement,  netwerk,  oost,  regio,  offlin,  vlaander\n",
      "-------------------\n",
      "voor\n",
      "nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen\n",
      "na\n",
      "nieuwjaarsreceptie,  netwerkevenement,  netwerk,  oost,  regio,  offlin,  vlaander\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='dutch')\n",
    "\n",
    "for i in range(5):\n",
    "  print(\"-------------------\")\n",
    "  print(\"voor\")\n",
    "  print(df_clean['campagne_keyphrases'][i])\n",
    "  print(\"na\")\n",
    "  stem_sentence=[]\n",
    "  for word in df_clean['campagne_keyphrases'][i].split(','):\n",
    "    stem_sentence.append(stemmer.stem(word))\n",
    "  stem_sentence= ', '.join(stem_sentence)\n",
    "  print(stem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "voor\n",
      "vastgoed, netwerkevenement, ov, kick, bouw, offline, community, off\n",
      "na\n",
      "vastgoed,  netwerkevenement,  ov,  kick,  bouw,  offline,  community,  off\n",
      "-------------------\n",
      "voor\n",
      "opleiding, sales, offline, corona, tables, round\n",
      "na\n",
      "opleiding,  sales,  offline,  corona,  tables,  round\n",
      "-------------------\n",
      "voor\n",
      "nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen\n",
      "na\n",
      "nieuwjaarsreceptie,  netwerkevenement,  netwerking,  oost,  regio,  offline,  vlaanderen\n",
      "-------------------\n",
      "voor\n",
      "nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen\n",
      "na\n",
      "nieuwjaarsreceptie,  netwerkevenement,  netwerking,  oost,  regio,  offline,  vlaanderen\n",
      "-------------------\n",
      "voor\n",
      "nieuwjaarsreceptie, netwerkevenement, netwerking, oost, regio, offline, vlaanderen\n",
      "na\n",
      "nieuwjaarsreceptie,  netwerkevenement,  netwerking,  oost,  regio,  offline,  vlaanderen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\storm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\storm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")\n",
    "\n",
    "# wnl = WordNetLemmatizer()\n",
    "\n",
    "# for i in range(5):\n",
    "#   print(\"-------------------\")\n",
    "#   print(\"voor\")\n",
    "#   print(df_clean['campagne_keyphrases'][i])\n",
    "#   print(\"na\")\n",
    "#   stem_sentence=[]\n",
    "#   for word in df_clean['campagne_keyphrases'][i].split(','):\n",
    "#     stem_sentence.append(wnl.lemmatize(word, pos='v'))\n",
    "#   stem_sentence= ', '.join(stem_sentence)\n",
    "#   print(stem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campagne_keyphrases embeddings: 6 minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    response = openai.Embedding.create(\n",
    "    input=text,\n",
    "    model=embedding_model\n",
    "    )   \n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "\n",
    "def embed_col(df, col):\n",
    "    unique_col = df[col].unique().tolist()\n",
    "    dict_temp = {}\n",
    "\n",
    "    for i in unique_col:\n",
    "        dict_temp[i] = get_embedding(i)\n",
    "    \n",
    "    df[col+'_embed'] = df[col].map(dict_temp)\n",
    "    df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_emb1 = embed_col(df=df_clean, col='campagne_keyphrases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean_emb1['campagne_keyphrases_embed'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Met OpenAI embedding -> 1536 getallen per keyphrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the value from each embedded column to a single value\n",
    "def reduce_embedding(embedded):\n",
    "    return np.mean(embedded)\n",
    "\n",
    "df_clean['campagne_naam_embedded'] = df_clean['campagne_naam_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['visit_ip_embedded'] = df_clean['visit_ip_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['afspraak_keyphrases_embedded'] = df_clean['afspraak_keyphrases_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['mailing_name_embedded'] = df_clean['mailing_name_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['mailing_onderwerp_embedded'] = df_clean['mailing_onderwerp_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5, ).fit(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 60\n",
      "Estimated number of noise points: 9604\n"
     ]
    }
   ],
   "source": [
    "labels_db = dbscan.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "n_noise_ = list(labels_db).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'eps': 0.5,\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'euclidean',\n",
       " 'metric_params': None,\n",
       " 'min_samples': 5,\n",
       " 'n_jobs': None,\n",
       " 'p': None}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.get_params(deep=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
