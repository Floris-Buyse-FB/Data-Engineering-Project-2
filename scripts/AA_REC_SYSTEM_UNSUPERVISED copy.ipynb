{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250666, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_clean/merged_total.csv')\n",
    "df.fillna('unknown', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\buyse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\buyse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['afspraak_keyphrases', 'account_keyphrases', 'campagne_keyphrases',\n",
       "       'sessie_keyphrases', 'visit_keyphrases', 'mailing_keyphrases'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "cat_cols = cat_cols[(cat_cols != 'visit_bounce') & (cat_cols != 'contact_contactpersoon_id') & (cat_cols != 'account_account_id')]\n",
    "\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afspraak_keyphrases</th>\n",
       "      <th>account_keyphrases</th>\n",
       "      <th>campagne_keyphrases</th>\n",
       "      <th>sessie_keyphrases</th>\n",
       "      <th>visit_keyphrases</th>\n",
       "      <th>mailing_keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>familiebedrijf, diensten, vastgoed, melle gent...</td>\n",
       "      <td>offline, netwerkevenement, ov kick off communi...</td>\n",
       "      <td>ma events, netwerking, netwerkactiviteit project</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>bedrijf, diensten, consultancy, geraardsbergen...</td>\n",
       "      <td>offline, opleiding, corona round tables sales</td>\n",
       "      <td>gr werking, marketing sales, opleidingen</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retentie lidmaatschap, ledenbezoek 2023, indus...</td>\n",
       "      <td>bedrijf, diensten, milieu, meilegem oudenaarde...</td>\n",
       "      <td>offline, netwerkevenement, nw nieuwjaarsrecept...</td>\n",
       "      <td>nw voka connect gent, netwerking, netwerkactiv...</td>\n",
       "      <td>chrome, windows, ghent, belgium, pro, event su...</td>\n",
       "      <td>jo stamgasten 2023, uitnodiging stamgasten 23 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retentie lidmaatschap, ledenbezoek 2023, indus...</td>\n",
       "      <td>bedrijf, diensten, milieu, meilegem oudenaarde...</td>\n",
       "      <td>offline, netwerkevenement, nw nieuwjaarsrecept...</td>\n",
       "      <td>nw voka connect gent, netwerking, netwerkactiv...</td>\n",
       "      <td>chrome, windows, ghent, belgium, telenet, acti...</td>\n",
       "      <td>nw nieuwjaarsreceptie vlaamse ardennen leiestr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retentie lidmaatschap, ledenbezoek 2023, indus...</td>\n",
       "      <td>bedrijf, diensten, milieu, meilegem oudenaarde...</td>\n",
       "      <td>offline, netwerkevenement, nw nieuwjaarsrecept...</td>\n",
       "      <td>nw voka connect gent, netwerking, netwerkactiv...</td>\n",
       "      <td>chrome, windows, ghent, belgium, pro, activite...</td>\n",
       "      <td>nieuwsbrief 09052023, nieuws van voka oost vla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 afspraak_keyphrases   \n",
       "0                                                  ,  \\\n",
       "1                                                  ,   \n",
       "2  retentie lidmaatschap, ledenbezoek 2023, indus...   \n",
       "3  retentie lidmaatschap, ledenbezoek 2023, indus...   \n",
       "4  retentie lidmaatschap, ledenbezoek 2023, indus...   \n",
       "\n",
       "                                  account_keyphrases   \n",
       "0  familiebedrijf, diensten, vastgoed, melle gent...  \\\n",
       "1  bedrijf, diensten, consultancy, geraardsbergen...   \n",
       "2  bedrijf, diensten, milieu, meilegem oudenaarde...   \n",
       "3  bedrijf, diensten, milieu, meilegem oudenaarde...   \n",
       "4  bedrijf, diensten, milieu, meilegem oudenaarde...   \n",
       "\n",
       "                                 campagne_keyphrases   \n",
       "0  offline, netwerkevenement, ov kick off communi...  \\\n",
       "1      offline, opleiding, corona round tables sales   \n",
       "2  offline, netwerkevenement, nw nieuwjaarsrecept...   \n",
       "3  offline, netwerkevenement, nw nieuwjaarsrecept...   \n",
       "4  offline, netwerkevenement, nw nieuwjaarsrecept...   \n",
       "\n",
       "                                   sessie_keyphrases   \n",
       "0   ma events, netwerking, netwerkactiviteit project  \\\n",
       "1           gr werking, marketing sales, opleidingen   \n",
       "2  nw voka connect gent, netwerking, netwerkactiv...   \n",
       "3  nw voka connect gent, netwerking, netwerkactiv...   \n",
       "4  nw voka connect gent, netwerking, netwerkactiv...   \n",
       "\n",
       "                                    visit_keyphrases   \n",
       "0                                            unknown  \\\n",
       "1                                            unknown   \n",
       "2  chrome, windows, ghent, belgium, pro, event su...   \n",
       "3  chrome, windows, ghent, belgium, telenet, acti...   \n",
       "4  chrome, windows, ghent, belgium, pro, activite...   \n",
       "\n",
       "                                  mailing_keyphrases  \n",
       "0                                            unknown  \n",
       "1                                            unknown  \n",
       "2  jo stamgasten 2023, uitnodiging stamgasten 23 ...  \n",
       "3  nw nieuwjaarsreceptie vlaamse ardennen leiestr...  \n",
       "4  nieuwsbrief 09052023, nieuws van voka oost vla...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['afspraak_keyphrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "def remove_stopwords(text):\n",
    "    stop_words_nl = set(stopwords.words('dutch'))\n",
    "    \n",
    "    word_tokens = word_tokenize(text, language='dutch')\n",
    "\n",
    "    result = [x for x in word_tokens if x not in stop_words_nl]\n",
    "\n",
    "    seperator = ', '\n",
    "    return seperator.join(result)\n",
    "\n",
    "\n",
    "def team_name_change(text):\n",
    "    teams_dict = {\n",
    "        'jo': ' jong ondernemen ',\n",
    "        'do': ' duurzaam ondernemen ',\n",
    "        'in': ' innovatie digitalisering ',\n",
    "        'io': ' internationaal ondernemen ',\n",
    "        'ao': ' arbeidsmarkt ',\n",
    "        'ex': ' expert ',\n",
    "        'gr': ' groei ',\n",
    "        'bb': ' belangenbehartiging ',\n",
    "        'co': ' communicatie ',\n",
    "        'nw': ' netwerking ',\n",
    "        'ha': ' haven ',\n",
    "        'ma': ' match '\n",
    "    }\n",
    "    word_tokens = word_tokenize(text, language='dutch')\n",
    "    # apply dict to list\n",
    "    result = [teams_dict.get(word, word) for word in word_tokens]\n",
    "    # join list to string\n",
    "    cleaned_list = ', '.join(result)\n",
    "    # tokenize string\n",
    "    tokenize_list = word_tokenize(cleaned_list, language='dutch')\n",
    "    # remove comma\n",
    "    tokenize_list_no_comma = [x for x in tokenize_list if x != ',']\n",
    "    # join list to string and remove duplicates from list\n",
    "    return ', '.join(list(set(tokenize_list_no_comma)))\n",
    "\n",
    "\n",
    "def stemmer(text):\n",
    "    stemmer = SnowballStemmer(language='dutch')\n",
    "    stem_sentence=[]\n",
    "    for word in text.split(','):\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "    stem_sentence= ', '.join(stem_sentence)\n",
    "    return stem_sentence\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(df, cat_cols=cat_cols):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        for row in range(len(df_copy)):\n",
    "            name_change = team_name_change(df_copy[col][row])\n",
    "            no_stopwords = remove_stopwords(name_change)\n",
    "            tokenize_list = word_tokenize(no_stopwords, language='dutch')\n",
    "            tokenize_list = [x for x in tokenize_list if x != ',']\n",
    "            df_copy.at[row, col] = ', '.join(list(set(tokenize_list)))\n",
    "            stemmer_list= stemmer(df_copy[col][row])\n",
    "            df_copy.at[row, col] = stemmer_list\n",
    "            \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def flatten_vector_columns(df, col):\n",
    "    # Flatten the 'vector_column' into a matrix (with padding)\n",
    "    max_vector_length = max(len(vector) for vector in df[col])\n",
    "    padded_matrix = np.array([vector + [0.0] * (max_vector_length - len(vector)) for vector in df[col]])\n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duurt 11.5 minuten om df_clean te maken (10cores) 30 min (4cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_text(df=df, cat_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].str.replace(r'\\d', '', regex=True).str.replace(', ,', ',')\n",
    "    df_clean[col] = df_clean[col].apply(lambda x: 'unknown' if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['campagne_keyphrases'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campagne_keyphrases embeddings: 6 minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    response = openai.Embedding.create(\n",
    "    input=text,\n",
    "    model=embedding_model\n",
    "    )   \n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "\n",
    "def embed_col(df, col):\n",
    "    unique_col = df[col].unique().tolist()\n",
    "    dict_temp = {}\n",
    "\n",
    "    for i in unique_col:\n",
    "        dict_temp[i] = get_embedding(i)\n",
    "    \n",
    "    df[col+'_embed'] = df[col].map(dict_temp)\n",
    "    df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_emb1 = embed_col(df=df_clean, col='campagne_keyphrases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean_emb1['campagne_keyphrases_embed'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Met OpenAI embedding -> 1536 getallen per keyphrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the value from each embedded column to a single value\n",
    "def reduce_embedding(embedded):\n",
    "    return np.mean(embedded)\n",
    "\n",
    "df_clean['campagne_naam_embedded'] = df_clean['campagne_naam_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['visit_ip_embedded'] = df_clean['visit_ip_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['afspraak_keyphrases_embedded'] = df_clean['afspraak_keyphrases_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['mailing_name_embedded'] = df_clean['mailing_name_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "df_clean['mailing_onderwerp_embedded'] = df_clean['mailing_onderwerp_embedded'].apply(lambda x: reduce_embedding(x))\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5, ).fit(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 60\n",
      "Estimated number of noise points: 9604\n"
     ]
    }
   ],
   "source": [
    "labels_db = dbscan.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "n_noise_ = list(labels_db).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'eps': 0.5,\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'euclidean',\n",
       " 'metric_params': None,\n",
       " 'min_samples': 5,\n",
       " 'n_jobs': None,\n",
       " 'p': None}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.get_params(deep=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
