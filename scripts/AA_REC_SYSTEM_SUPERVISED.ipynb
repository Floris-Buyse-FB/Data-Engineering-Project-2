{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/AA_Supervised_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opsplitting in X en y\n",
    "X = df.drop('Ingeschreven', axis=1)\n",
    "y = df['Ingeschreven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opsplitting in train en test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=df['Ingeschreven'])\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = []\n",
    "\n",
    "def models_gs(model):\n",
    "    try:\n",
    "        grid_search = GridSearchCV(model[\"model\"], param_grid=model[\"param_grid\"], cv=5, scoring=\"accuracy\", return_train_score=True, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "    \n",
    "        best_model = grid_search.best_estimator_.named_steps[model[\"name\"].lower()]\n",
    "        return (best_model, grid_search.best_score_)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"{model['name']} failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ensemble_models_param_grid = [\n",
    "   {\n",
    "      \"name\":\"linearsvc\",\n",
    "      \"model\": LinearSVC(random_state=42),\n",
    "      \"param_grid\": {\n",
    "         \"linearsvc__C\":[0.1, 0.5, 1, 2.5, 5, 10, 20, 50, 75, 100, 125, 150, 200, 250, 500, 1000],\n",
    "         \"linearsvc__penalty\": [\"l2\"],\n",
    "         \"linearsvc__loss\": [\"loss\", \"log_loss\", \"hinge\", \"squared_hinge\"],\n",
    "      }\n",
    "   },\n",
    "   {\n",
    "      \"name\":\"sgdclassifier\",\n",
    "      \"model\": SGDClassifier(loss=\"log\", random_state=42), # loss=\"log\" because we want to use the predict_proba method, this is not possible with hinge loss\n",
    "      \"param_grid\":{\n",
    "         \"sgdclassifier__alpha\":[0.001, 0.01, 0.1, 0.5, 1],\n",
    "         \"sgdclassifier__penalty\":[\"l2\"],\n",
    "         \"sgdclassifier__max_iter\": [1000]\n",
    "      }\n",
    "   },\n",
    "   {\n",
    "      \"name\":\"logisticregression\",\n",
    "      \"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "      \"param_grid\":{\n",
    "         \"logisticregression__C\":[0.1, 0.5, 1, 2.5, 5, 10, 20, 50, 75, 100, 125, 150, 200, 250, 500, 1000],\n",
    "         \"logisticregression__penalty\":[\"l2\"]\n",
    "      }\n",
    "   },\n",
    "   {\n",
    "      \"name\":\"decisiontreeclassifier\",\n",
    "      \"model\": DecisionTreeClassifier(random_state=42),\n",
    "      \"param_grid\":{\n",
    "         \"decisiontreeclassifier__max_depth\":[5, 10, 15, 20, 25, 30],\n",
    "         \"decisiontreeclassifier__min_samples_split\":[2, 5, 10, 15],\n",
    "         \"decisiontreeclassifier__min_samples_leaf\":[2, 5, 10, 15],\n",
    "      }\n",
    "   },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in non_ensemble_models_param_grid:\n",
    "  print(f'Starting {model[\"name\"]}...')\n",
    "  gs = models_gs(model)\n",
    "  print(gs)\n",
    "  best_models.append({\n",
    "      \"name\": model[\"name\"],\n",
    "      \"model\": gs[0],\n",
    "      \"gs_score\": gs[1],\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best_models:\n",
    "  cv_score = cross_val_score(model[\"model\"], X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "  print(f'{model[\"name\"]} - cross validation scores: {np.mean(cv_score)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = {\n",
    "      \"name\":\"randomforestclassifier\",\n",
    "      \"model\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "      \"param_grid\":{\n",
    "         \"randomforestclassifier__n_estimators\":[50, 75, 100, 125, 150, 175, 200],\n",
    "         \"randomforestclassifier__min_samples_split\":[2, 5, 10],\n",
    "         \"randomforestclassifier__min_samples_leaf\":[2, 5, 10],\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting {rfc['name']}...\")\n",
    "gs = models_gs(rfc)\n",
    "print(gs)\n",
    "best_models.append({\n",
    "    \"name\": f\"{rfc['name']}\",\n",
    "    \"model\": gs[0],\n",
    "    \"gs_score\": gs[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clfs = [\n",
    "    {\n",
    "        \"name\": \"votingclassifier\",\n",
    "        \"diff\": \"hard\",\n",
    "        \"model\": VotingClassifier(estimators=[\n",
    "            ('linsvc', best_models[0]['model']),\n",
    "            ('sgd', best_models[1]['model']),\n",
    "            ('lr', best_models[2]['model']),\n",
    "            ('dt', best_models[3]['model']),\n",
    "            ('rf', best_models[4]['model']),\n",
    "        ], voting='hard', n_jobs=-1),\n",
    "        \"param_grid\": {\n",
    "            'votingclassifier__weights': [\n",
    "                [1, 1, 1, 1, 1],\n",
    "                [1, 1, 1, 1, 2], \n",
    "                [1, 1, 1, 2, 2], \n",
    "                [1, 1, 2, 2, 2], \n",
    "                [1, 2, 2, 2, 2],\n",
    "                [2, 2, 2, 2, 2]\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"votingclassifier\",\n",
    "        \"diff\": \"soft\",\n",
    "        \"model\": VotingClassifier(estimators=[\n",
    "            ('sgd', best_models[1]['model']),\n",
    "            ('lr', best_models[2]['model']),\n",
    "            ('dt', best_models[3]['model']),\n",
    "            ('rf', best_models[4]['model']),\n",
    "        ], voting='soft', n_jobs=-1),\n",
    "        \"param_grid\": {\n",
    "            'votingclassifier__weights': [\n",
    "                [1, 1, 1, 1], \n",
    "                [1, 1, 1, 2], \n",
    "                [1, 1, 2, 2], \n",
    "                [1, 2, 2, 2], \n",
    "                [2, 2, 2, 2]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in voting_clfs:\n",
    "    print(f\"Starting {model['diff']}-voting model...\")\n",
    "    gs = models_gs({\n",
    "        \"name\": model[\"name\"],\n",
    "        \"model\": model[\"model\"],\n",
    "        \"param_grid\": model[\"param_grid\"]\n",
    "    })\n",
    "    print(gs)\n",
    "    best_models.append({\n",
    "        \"name\": f\"voting_{model['diff']}\",\n",
    "        \"model\": gs[0],\n",
    "        \"gs_score\": gs[1],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clf = {\n",
    "    \"name\": 'BaggingClassifier',\n",
    "    \"model\": BaggingClassifier(random_state=42, n_jobs=-1, oob_score=True),\n",
    "    \"param_grid\": {\n",
    "        \"baggingclassifier__estimator\": [best_models[3][\"model\"]],\n",
    "        \"baggingclassifier__n_estimators\": [10, 50, 100, 150],\n",
    "        \"baggingclassifier__bootstrap\": [True, False],\n",
    "        \"baggingclassifier__max_samples\": [0.5, 1.0, 2.0, 5.0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting {bagging_clf['name']}...\")\n",
    "gs = models_gs(bagging_clf)\n",
    "print(gs)\n",
    "print(f\"OOB score: {gs[0].oob_score_}\")\n",
    "best_models.append({\n",
    "    \"name\": f\"{bagging_clf['name']}\",\n",
    "    \"model\": gs[0],\n",
    "    \"gs_score\": gs[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf = {\n",
    "    \"name\": 'AdaBoostClassifier',\n",
    "    \"model\": AdaBoostClassifier(random_state=42),\n",
    "    \"param_grid\": {\n",
    "        \"adaboostclassifier__base_estimator\": [best_models[3][\"model\"]],\n",
    "        \"adaboostclassifier__n_estimators\": [10, 50, 100, 150],\n",
    "        \"adaboostclassifier__learning_rate\": [0.1, 0.5, 1.0, 2.0],\n",
    "        \"adaboostclassifier__algorithm\": ['SAMME.R']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting {adaboost_clf['name']}...\")\n",
    "gs = models_gs(adaboost_clf)\n",
    "print(gs)\n",
    "best_models.append({\n",
    "    \"name\": f\"{adaboost_clf['name']}\",\n",
    "    \"model\": gs[0],\n",
    "    \"gs_score\": gs[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_clf = {\n",
    "    \"name\": 'GradientBoostingClassifier',\n",
    "    \"model\": GradientBoostingClassifier(random_state=42),\n",
    "    \"param_grid\": {\n",
    "        \"gradientboostingclassifier__n_estimators\": [10, 50, 100, 150],\n",
    "        \"gradientboostingclassifier__learning_rate\": [0.1, 0.5, 1.0, 2.0],\n",
    "        \"gradientboostingclassifier__min_samples_split\": [2, 5, 10],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting {gradient_boosting_clf['name']}...\")\n",
    "gs = models_gs(gradient_boosting_clf)\n",
    "print(gs)\n",
    "best_models.append({\n",
    "    \"name\": f\"{gradient_boosting_clf['name']}\",\n",
    "    \"model\": gs[0],\n",
    "    \"gs_score\": gs[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('sgd', best_models[1]['model']),\n",
    "    ('lr', best_models[2]['model']),\n",
    "    ('dt', best_models[3]['model']),\n",
    "    ('rf', best_models[4]['model']),\n",
    "]\n",
    "\n",
    "final_estimators = [\n",
    "    ('sgd', SGDClassifier(random_state=42, loss='log')),\n",
    "    ('lr', LogisticRegression(random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "]\n",
    "\n",
    "stacking_clfs = [\n",
    "    {\n",
    "        \"name\": 'StackingClassifier',\n",
    "        \"diff\": final_estimators[0][0],\n",
    "        \"model\": StackingClassifier(estimators=estimators, final_estimator=final_estimators[0][1], n_jobs=-1),\n",
    "        \"param_grid\": {}\n",
    "    },\n",
    "    {\n",
    "        \"name\": 'StackingClassifier',\n",
    "        \"diff\": final_estimators[1][0],\n",
    "        \"model\": StackingClassifier(estimators=estimators, final_estimator=final_estimators[1][1], n_jobs=-1),\n",
    "        \"param_grid\": {}\n",
    "    },\n",
    "    {\n",
    "        \"name\": 'StackingClassifier',\n",
    "        \"diff\": final_estimators[2][0],\n",
    "        \"model\": StackingClassifier(estimators=estimators, final_estimator=final_estimators[2][1], n_jobs=-1),\n",
    "        \"param_grid\": {}\n",
    "    },\n",
    "    {\n",
    "        \"name\": 'StackingClassifier',\n",
    "        \"diff\": final_estimators[3][0],\n",
    "        \"model\": StackingClassifier(estimators=estimators, final_estimator=final_estimators[3][1], n_jobs=-1),\n",
    "        \"param_grid\": {}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stacking_clfs:\n",
    "    print(f\"Starting {i['name']}_{i['diff']}...\")\n",
    "    gs = models_gs(i)\n",
    "    print(gs)\n",
    "    best_models.append({\n",
    "        \"name\": f\"{i['name']}_{i['diff']}\",\n",
    "        \"model\": gs[0],\n",
    "        \"gs_score\": gs[1],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame(columns=[\"Name\", \"gs_score\", \"cv_score\", \"precision\", \"recall\", \"f1\", \"roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best_models:\n",
    "    scores = cross_val_score(model[\"model\"], X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    y_train_pred = cross_val_predict(model[\"model\"], X_train, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "    precision = precision_score(y_train, y_train_pred)\n",
    "    recall = recall_score(y_train, y_train_pred)\n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    model_comparison = model_comparison.append({\n",
    "        \"Name\": model[\"name\"],\n",
    "        \"gs_score\": model[\"gs_score\"],\n",
    "        \"cv_score\": scores.mean(),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison.sort_values(by=\"precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_test = pd.DataFrame(columns=[\"Name\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "  plt.figure(figsize=(6, 5))\n",
    "  plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "  plt.plot([0, 1], [0, 1], 'k--', label=\"Random classifier's ROC curve\")\n",
    "  plt.title(f\"{label} - Test\")\n",
    "  plt.legend(loc=\"lower right\", fontsize=13)\n",
    "  plt.xlabel(\"True Positive Rate (Recall)\")\n",
    "  plt.ylabel(\"False Positive Rate (Fall-Out)\")\n",
    "  plt.grid(True)\n",
    "  plt.axis([0, 1, 0, 1])\n",
    "  plt.figure(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best_models:\n",
    "    X_test_scaled = col_transformer.fit_transform(X_test)\n",
    "    y_test_pred = model[\"model\"].predict(X_test_scaled)\n",
    "\n",
    "    plt.figure()\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred, normalize=\"true\", values_format='.0%')\n",
    "    plt.title(f\"{model['name']} - Test\")\n",
    "    plt.show()\n",
    "\n",
    "    score = accuracy_score(y_test, y_test_pred) \n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    plt.figure()\n",
    "    plot_roc_curve(fpr, tpr, label=model[\"name\"])\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{model['name']} - Test\")\n",
    "    print(f\"Accuracy: {score.mean()}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(f\"ROC AUC: {roc_auc}\")\n",
    "    print(75 * \"*\")\n",
    "\n",
    "    model_comparison_test = model_comparison_test.append({\n",
    "        \"Name\": model[\"name\"],\n",
    "        \"accuracy\": score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "\n",
    "# stacking_sgd = best_models[10]\n",
    "# filename = f'models/weblogs_{stacking_sgd[\"name\"]}.pkl'\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pkl.dump(stacking_sgd[\"model\"], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
